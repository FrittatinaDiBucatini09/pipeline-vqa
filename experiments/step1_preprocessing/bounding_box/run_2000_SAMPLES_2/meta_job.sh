#!/bin/bash
# ==============================================================================
# AUTO-GENERATED META-JOB: Medical VQA Pipeline
# Generated by the Pipeline Orchestrator
# ==============================================================================

#SBATCH --job-name=vqa_pipeline
#SBATCH --output=/home/rbalzani/medical-vqa/Thesis/orchestrator_runs/run_20260217_120712/slurm_metajob_%j.out
#SBATCH --error=/home/rbalzani/medical-vqa/Thesis/orchestrator_runs/run_20260217_120712/slurm_metajob_%j.err
#SBATCH -N 1
#SBATCH --gpus=nvidia_geforce_rtx_3090:1
#SBATCH -w faretra
#SBATCH --time=15:00:00
# Send SIGTERM 60s before SIGKILL on timeout, so trap can clean up
#SBATCH --signal=B:TERM@60

# Fail-fast: exit immediately if any command fails
set -e

# ==============================================================================
# GLOBAL ENVIRONMENT
# ==============================================================================
export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
export ORCH_OUTPUT_DIR="/home/rbalzani/medical-vqa/Thesis/orchestrator_runs/run_20260217_120712"
export DATA_FILE_OVERRIDE="mimic_ext_stratified_2000_samples.csv"

# ==============================================================================
# ERROR HANDLING & REPORTING
# ==============================================================================
CURRENT_STEP="initializing"
PIPELINE_START=$(date '+%Y-%m-%d %H:%M:%S')

# Snapshot running containers before pipeline starts
PRE_CONTAINERS=$(docker ps -q 2>/dev/null | sort)

cleanup() {
    EXIT_CODE=$?
    TIMESTAMP=$(date '+%Y-%m-%d %H:%M:%S')

    # Kill any Docker containers started during this meta-job
    POST_CONTAINERS=$(docker ps -q 2>/dev/null | sort)
    NEW_CONTAINERS=$(comm -13 <(echo "$PRE_CONTAINERS") <(echo "$POST_CONTAINERS") 2>/dev/null)
    if [ -n "$NEW_CONTAINERS" ]; then
        echo "[$TIMESTAMP] Stopping orphan Docker containers..."
        docker kill $NEW_CONTAINERS 2>/dev/null || true
        sleep 2
    fi

    echo ''
    echo '============================================================'
    if [ $EXIT_CODE -ne 0 ]; then
        echo "[$TIMESTAMP] PIPELINE FAILED at step: $CURRENT_STEP"
        echo "Exit code: $EXIT_CODE"
        echo "Started:   $PIPELINE_START"
        echo "Failed:    $TIMESTAMP"
    else
        echo "[$TIMESTAMP] PIPELINE COMPLETED SUCCESSFULLY"
        echo "Started:  $PIPELINE_START"
        echo "Finished: $TIMESTAMP"
    fi
    echo '============================================================'
}
trap cleanup EXIT
trap 'exit 143' TERM  # Ensure SIGTERM (from SLURM timeout) triggers EXIT trap

echo "============================================================"
echo "Medical VQA Pipeline - Meta-Job"
echo "Run directory: /home/rbalzani/medical-vqa/Thesis/orchestrator_runs/run_20260217_120712"
echo "Stages: 4"
echo "Dataset override: mimic_ext_stratified_2000_samples.csv"
echo "============================================================"

# ==============================================================================
# STEP 1: Preprocessing: Attention Map
# ==============================================================================
CURRENT_STEP="1 - Preprocessing: Attention Map"
echo "[$(date '+%Y-%m-%d %H:%M:%S')] START: $CURRENT_STEP"

cd "/home/rbalzani/medical-vqa/Thesis/preprocessing/attention_map"
bash submit_heatmap_gen.sh configs/exp/S_question_T0.30_C_crf_on_P_smart.conf

echo "[$(date '+%Y-%m-%d %H:%M:%S')] DONE:  $CURRENT_STEP"

# ==============================================================================
# STEP 2: Routing: NLP Query Expansion
# ==============================================================================
CURRENT_STEP="2 - Routing: NLP Query Expansion"
echo "[$(date '+%Y-%m-%d %H:%M:%S')] START: $CURRENT_STEP"

cd "/home/rbalzani/medical-vqa/Thesis/preprocessing/medclip_routing"
bash submit_routing.sh configs/default.conf

echo "[$(date '+%Y-%m-%d %H:%M:%S')] DONE:  $CURRENT_STEP"

# ==============================================================================
# STEP 3: VQA Generation
# ==============================================================================
CURRENT_STEP="3 - VQA Generation"
echo "[$(date '+%Y-%m-%d %H:%M:%S')] START: $CURRENT_STEP"

cd "/home/rbalzani/medical-vqa/Thesis/vqa"
bash submit_generation.sh configs/generation/hard_coded_gen.conf

echo "[$(date '+%Y-%m-%d %H:%M:%S')] DONE:  $CURRENT_STEP"

# ==============================================================================
# STEP 4: VQA Evaluation (Judge)
# ==============================================================================
CURRENT_STEP="4 - VQA Evaluation (Judge)"
echo "[$(date '+%Y-%m-%d %H:%M:%S')] START: $CURRENT_STEP"

cd "/home/rbalzani/medical-vqa/Thesis/vqa" || exit 1
PHYS_DIR=$(pwd)

# Load HF_TOKEN from .env if not already set
if [ -z "$HF_TOKEN" ] && [ -f "$PHYS_DIR/.env" ]; then
    echo "  Loading secrets from .env..."
    set -a
    source "$PHYS_DIR/.env"
    set +a
fi

IMAGE_NAME="med_vqa_project:3090"

# Verify Docker image exists
if [[ -z "$(docker images -q "$IMAGE_NAME" 2>/dev/null)" ]]; then
    echo "[ERROR] Docker image '$IMAGE_NAME' not found. Build it first."
    exit 1
fi

echo "  Launching VQA Judge container..."
echo "  Config: configs/judge/hard_coded_judge.conf"

docker run --rm \
    --name "metajob_${SLURM_JOB_ID:-local}_judge" \
    --gpus "device=${CUDA_VISIBLE_DEVICES:-0}" \
    --shm-size=16g \
    -v "$PHYS_DIR":/workspace \
    -v /llms:/llms \
    -e HF_HOME=/llms \
    -e HF_TOKEN="${HF_TOKEN:-}" \
    "$IMAGE_NAME" \
    /bin/bash /workspace/scripts/run_judge.sh "configs/judge/hard_coded_judge.conf"

echo "[$(date '+%Y-%m-%d %H:%M:%S')] DONE:  $CURRENT_STEP"
